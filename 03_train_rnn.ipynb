{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3bNFYl6IHOM0CihYmZ7lT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulienHelfenstein/World_model/blob/main/03_train_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Définir le chemin racine de votre projet\n",
        "PROJECT_ROOT = \"/content/drive/My Drive/Colab Notebooks/World_model\""
      ],
      "metadata": {
        "id": "OyWAXTPNTk4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3Rlre33M8db"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from torch.distributions import Categorical, Normal, MixtureSameFamily"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Configuration et Hyperparamètres ---\n",
        "VAE_MODEL_PATH = os.path.join(PROJECT_ROOT, \"vae.pth\")\n",
        "DATA_FILE = os.path.join(PROJECT_ROOT, \"data/carracing_data.npz\")\n",
        "RNN_DATA_FILE = os.path.join(PROJECT_ROOT, \"data/rnn_data.npz\")\n",
        "RNN_MODEL_PATH = os.path.join(PROJECT_ROOT, \"rnn.pth\")\n",
        "\n",
        "# Paramètres (doivent correspondre au VAE et aux données)\n",
        "z_dim = 32\n",
        "action_dim = 3  # CarRacing: [steer, gas, brake]\n",
        "hidden_dim = 256 # Taille de la mémoire du LSTM\n",
        "num_mixtures = 5 # Nombre de \"futurs\" possibles à prédire\n",
        "seq_length = 50  # Longueur des séquences pour l'entraînement du RNN\n",
        "batch_size = 32\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 10  # 10-20 époques est un bon début\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "tblkqomHNZRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Définition des Modèles ---\n",
        "\n",
        "# On a besoin de la *définition* du CVAE pour charger le state_dict\n",
        "# (copié-collé de train_vae_carracing.py)\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, z_dim, image_channels=3):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "        self.flat_size = 256 * 4 * 4\n",
        "        self.fc_mu = nn.Linear(self.flat_size, z_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flat_size, z_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h_flat = h.view(-1, self.flat_size)\n",
        "        return self.fc_mu(h_flat), self.fc_logvar(h_flat)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    # Le décodeur n'est pas nécessaire ici, mais on garde encode/reparam\n",
        "\n",
        "# Le \"Moteur de Rêve\" (MDN-RNN)\n",
        "\n",
        "class MDNRNN(nn.Module):\n",
        "    def __init__(self, z_dim, action_dim, hidden_dim, num_mixtures):\n",
        "        super(MDNRNN, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_mixtures = num_mixtures\n",
        "\n",
        "        input_dim = z_dim + action_dim\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        mdn_output_dim = num_mixtures * (1 + 2 * z_dim)\n",
        "        self.mdn_output = nn.Linear(hidden_dim, mdn_output_dim)\n",
        "\n",
        "    def forward(self, z_seq, a_seq, hidden_state):\n",
        "        # z_seq shape: (batch_size, seq_len, z_dim)\n",
        "        # a_seq shape: (batch_size, seq_len, action_dim)\n",
        "        lstm_input = torch.cat([z_seq, a_seq], dim=-1)\n",
        "\n",
        "        # lstm_output shape: (batch_size, seq_len, hidden_dim)\n",
        "        lstm_output, next_hidden = self.lstm(lstm_input, hidden_state)\n",
        "\n",
        "        # mdn_params shape: (batch_size, seq_len, mdn_output_dim)\n",
        "        mdn_params = self.mdn_output(lstm_output)\n",
        "\n",
        "        distribution = self.get_mixture_distribution(mdn_params)\n",
        "        return distribution, next_hidden\n",
        "\n",
        "    def get_mixture_distribution(self, mdn_params):\n",
        "        # Sépare les paramètres (batch_size, seq_len, N_mix * (1 + 2*z_dim))\n",
        "        # en pi, mu, sigma\n",
        "\n",
        "        # pi_logits shape: (batch_size, seq_len, num_mixtures)\n",
        "        pi_logits = mdn_params[..., :self.num_mixtures]\n",
        "\n",
        "        # mu shape: (batch_size, seq_len, num_mixtures, z_dim)\n",
        "        mu = mdn_params[..., self.num_mixtures : self.num_mixtures * (1 + self.z_dim)]\n",
        "        mu = mu.view(mdn_params.size(0), mdn_params.size(1), self.num_mixtures, self.z_dim)\n",
        "\n",
        "        # log_sigma shape: (batch_size, seq_len, num_mixtures, z_dim)\n",
        "        log_sigma = mdn_params[..., self.num_mixtures * (1 + self.z_dim) :]\n",
        "        log_sigma = log_sigma.view(mdn_params.size(0), mdn_params.size(1), self.num_mixtures, self.z_dim)\n",
        "\n",
        "        pi_dist = Categorical(logits=pi_logits)\n",
        "        sigma = torch.exp(log_sigma) + 1e-6\n",
        "        gaussian_dist = Normal(loc=mu, scale=sigma)\n",
        "\n",
        "        # Note: We need to expand gaussian_dist to match dimensions for MixtureSameFamily\n",
        "        # This is a bit advanced, but it's needed for batching sequences\n",
        "        mixture_dist = MixtureSameFamily(pi_dist, gaussian_dist)\n",
        "        return mixture_dist"
      ],
      "metadata": {
        "id": "xTW29h5nNWsU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Fonction de Perte (Loss) du MDN ---\n",
        "def mdn_loss_function(mixture_distribution, target_z):\n",
        "    # target_z shape: (batch_size, seq_len, z_dim)\n",
        "    # Le 'log_prob' du mélange a besoin que la cible soit \"expand\"\n",
        "    # pour correspondre à la forme (batch_size, seq_len, num_mixtures, z_dim)\n",
        "    target_z_expanded = target_z.unsqueeze(2).expand_as(mixture_distribution.component_distribution.loc)\n",
        "\n",
        "    log_prob = mixture_distribution.log_prob(target_z_expanded)\n",
        "\n",
        "    # On moyenne sur le batch et la séquence, et on minimise le négatif\n",
        "    return -torch.mean(log_prob)"
      ],
      "metadata": {
        "id": "P5N2QbixNTRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Phase 2a: Pré-traitement des données (VAE -> Z) ---\n",
        "def create_rnn_data():\n",
        "    if os.path.exists(RNN_DATA_FILE):\n",
        "        print(f\"Le fichier de données pré-traitées {RNN_DATA_FILE} existe déjà.\")\n",
        "        return\n",
        "\n",
        "    print(\"Phase 2a: Pré-traitement des données (Images -> Vecteurs Z)...\")\n",
        "\n",
        "    # 1. Charger le VAE entraîné\n",
        "    vae_model = CVAE(z_dim).to(device)\n",
        "    vae_model.load_state_dict(torch.load(VAE_MODEL_PATH, map_location=device))\n",
        "    vae_model.eval() # Mode évaluation (gèle les poids)\n",
        "\n",
        "    # 2. Charger les données brutes (images + actions)\n",
        "    raw_data = np.load(DATA_FILE)\n",
        "    observations = raw_data['observations'] # shape (N, 64, 64, 3)\n",
        "    actions = raw_data['actions']           # shape (N, 3)\n",
        "\n",
        "    # 3. Transformer les images en tenseurs (N, C, H, W)\n",
        "    obs_tensor = torch.from_numpy(observations).permute(0, 3, 1, 2).to(device, dtype=torch.float32)\n",
        "\n",
        "    z_vectors = []\n",
        "\n",
        "    # 4. Encoder toutes les images en vecteurs Z\n",
        "    # On traite par petits batchs pour ne pas saturer la VRAM\n",
        "    vae_batch_size = 256\n",
        "    with torch.no_grad(): # TRES IMPORTANT: pas de calcul de gradient\n",
        "        pbar = tqdm(range(0, len(obs_tensor), vae_batch_size), desc=\"Encodage VAE\")\n",
        "        for i in pbar:\n",
        "            batch_obs = obs_tensor[i : i + vae_batch_size]\n",
        "            mu, log_var = vae_model.encode(batch_obs)\n",
        "            z = vae_model.reparameterize(mu, log_var)\n",
        "            z_vectors.append(z.cpu().numpy()) # Stocker sur CPU\n",
        "\n",
        "    # 5. Concaténer et sauvegarder\n",
        "    all_z = np.concatenate(z_vectors, axis=0)\n",
        "    all_actions = actions # Les actions n'ont pas besoin de changer\n",
        "\n",
        "    print(f\"Encodage terminé. Shape Z: {all_z.shape}, Shape A: {all_actions.shape}\")\n",
        "    np.savez_compressed(RNN_DATA_FILE, z_vectors=all_z, actions=all_actions)\n",
        "    print(f\"Données pré-traitées sauvegardées dans {RNN_DATA_FILE}\")"
      ],
      "metadata": {
        "id": "4kfxMIlfNRe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Phase 2b: Dataset pour Séquences ---\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, data_file, seq_length):\n",
        "        data = np.load(data_file)\n",
        "        self.z_vectors = torch.from_numpy(data['z_vectors']).float()\n",
        "        self.actions = torch.from_numpy(data['actions']).float()\n",
        "        self.seq_length = seq_length\n",
        "\n",
        "    def __len__(self):\n",
        "        # On ne peut pas commencer une séquence près de la fin\n",
        "        return len(self.z_vectors) - self.seq_length - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Séquence d'entrée\n",
        "        z_seq = self.z_vectors[idx : idx + self.seq_length]\n",
        "        a_seq = self.actions[idx : idx + self.seq_length]\n",
        "\n",
        "        # Séquence cible (décalée d'un pas dans le temps)\n",
        "        target_z_seq = self.z_vectors[idx + 1 : idx + self.seq_length + 1]\n",
        "\n",
        "        return z_seq, a_seq, target_z_seq"
      ],
      "metadata": {
        "id": "1XtKAz49NPEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Script Principal d'Entraînement (Phase 2b) ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. Lancer la phase 2a (pré-traitement)\n",
        "    create_rnn_data()\n",
        "\n",
        "    print(\"Phase 2b: Entraînement du MDN-RNN...\")\n",
        "\n",
        "    # 2. Créer le Dataset et le DataLoader\n",
        "    dataset = SequenceDataset(RNN_DATA_FILE, seq_length)\n",
        "    data_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    # 3. Initialiser le Modèle et l'Optimiseur\n",
        "    model = MDNRNN(z_dim, action_dim, hidden_dim, num_mixtures).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    model.train() # Mode entraînement\n",
        "\n",
        "    # 4. Boucle d'Entraînement\n",
        "    for epoch in range(num_epochs):\n",
        "        pbar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        total_epoch_loss = 0\n",
        "\n",
        "        for z_seq, a_seq, target_z_seq in pbar:\n",
        "            z_seq = z_seq.to(device)\n",
        "            a_seq = a_seq.to(device)\n",
        "            target_z_seq = target_z_seq.to(device)\n",
        "\n",
        "            # Initialiser l'état caché (h, c) pour le LSTM\n",
        "            hidden_state = (torch.zeros(1, batch_size, hidden_dim).to(device),\n",
        "                            torch.zeros(1, batch_size, hidden_dim).to(device))\n",
        "\n",
        "            # --- Forward pass ---\n",
        "            # Gérer le dernier batch (qui peut être plus petit)\n",
        "            if z_seq.size(0) != batch_size:\n",
        "                hidden_state = (torch.zeros(1, z_seq.size(0), hidden_dim).to(device),\n",
        "                                torch.zeros(1, z_seq.size(0), hidden_dim).to(device))\n",
        "\n",
        "            distribution, _ = model(z_seq, a_seq, hidden_state)\n",
        "\n",
        "            # --- Calcul de la perte ---\n",
        "            loss = mdn_loss_function(distribution, target_z_seq)\n",
        "\n",
        "            # --- Backward pass ---\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_epoch_loss += loss.item()\n",
        "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "        avg_loss = total_epoch_loss / len(data_loader)\n",
        "        print(f\"Fin Epoch {epoch+1}. Perte moyenne : {avg_loss:.4f}\")\n",
        "\n",
        "    # 5. Sauvegarder le modèle\n",
        "    print(\"Entraînement du RNN terminé.\")\n",
        "    torch.save(model.state_dict(), RNN_MODEL_PATH)\n",
        "    print(f\"Modèle RNN sauvegardé dans {RNN_MODEL_PATH}\")"
      ],
      "metadata": {
        "id": "WQM059OLNM3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}