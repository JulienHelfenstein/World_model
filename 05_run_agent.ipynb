{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOweLeO+Ez9jeitqkklOBgP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulienHelfenstein/World_model/blob/main/05_run_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[box2d] numpy torch opencv-python tqdm pyvirtualdisplay xvfbwrapper &> /dev/null\n",
        "!pip install swig\n",
        "!pip install \"gymnasium[box2d]\" pyvirtualdisplay xvfbwrapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bwO0wvmT67-",
        "outputId": "70bfcc1d-ecc6-4d09-c5b0-3829d68d971f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.12/dist-packages (3.0)\n",
            "Requirement already satisfied: xvfbwrapper in /usr/local/lib/python3.12/dist-packages (0.2.15)\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.3.5)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Requirement already satisfied: swig==4.* in /usr/local/lib/python3.12/dist-packages (from gymnasium[box2d]) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o0Iyv6RqOcmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cb919cf-1c11-4d9e-bd4d-760fdb4f5cf2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import gymnasium\n",
        "import numpy as np\n",
        "import os\n",
        "from time import sleep\n",
        "from google.colab import drive\n",
        "from pyvirtualdisplay import Display\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "from glob import glob\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Configurer l'affichage virtuel (nécessaire pour Colab)\n",
        "display_colab = Display(visible=0, size=(1400, 900))\n",
        "display_colab.start()\n",
        "\n",
        "# Monter Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ROOT = \"/content/drive/My Drive/Colab Notebooks/World_model\"\n",
        "VIDEO_DIR = os.path.join(PROJECT_ROOT, \"videos\")\n",
        "\n",
        "# S'assurer que le dossier vidéo existe\n",
        "if not os.path.exists(VIDEO_DIR):\n",
        "    os.makedirs(VIDEO_DIR)\n",
        "\n",
        "VAE_MODEL_PATH = os.path.join(PROJECT_ROOT, \"vae.pth\")\n",
        "RNN_MODEL_PATH = os.path.join(PROJECT_ROOT, \"rnn.pth\")\n",
        "CONTROLLER_SAVE_PATH = os.path.join(PROJECT_ROOT, \"controller.pth\")\n",
        "\n",
        "z_dim = 32\n",
        "action_dim = 3\n",
        "hidden_dim = 256\n",
        "num_mixtures = 5\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Utilisation du device : {device}\")"
      ],
      "metadata": {
        "id": "zFVw7r5qOs9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d4d00a-dca9-4c5f-8e1d-4ab917e8aec3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utilisation du device : cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(nn.Module):\n",
        "    def __init__(self, z_dim, image_channels=3):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "        self.flat_size = 256 * 4 * 4\n",
        "        self.fc_mu = nn.Linear(self.flat_size, z_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flat_size, z_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x); h_flat = h.view(-1, self.flat_size)\n",
        "        return self.fc_mu(h_flat), self.fc_logvar(h_flat)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var); eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "class MDNRNN(nn.Module):\n",
        "    def __init__(self, z_dim, action_dim, hidden_dim, num_mixtures):\n",
        "        super(MDNRNN, self).__init__()\n",
        "        self.z_dim = z_dim; self.hidden_dim = hidden_dim; self.num_mixtures = num_mixtures\n",
        "        input_dim = z_dim + action_dim\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "        mdn_output_dim = num_mixtures * (1 + 2 * z_dim)\n",
        "        self.mdn_output = nn.Linear(hidden_dim, mdn_output_dim)\n",
        "        self.reward_head = nn.Linear(hidden_dim, 1)\n",
        "        self.done_head = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, z_t, a_t, hidden_state):\n",
        "        lstm_input = torch.cat([z_t, a_t], dim=-1).unsqueeze(1)\n",
        "        lstm_output, next_hidden = self.lstm(lstm_input, hidden_state)\n",
        "        lstm_output = lstm_output.squeeze(1)\n",
        "        mdn_params = self.mdn_output(lstm_output)\n",
        "        pred_reward = self.reward_head(lstm_output)\n",
        "        pred_done_logits = self.done_head(lstm_output)\n",
        "        return mdn_params, pred_reward, pred_done_logits, next_hidden\n",
        "\n",
        "class Controller(nn.Module):\n",
        "    def __init__(self, z_dim, hidden_dim, action_dim):\n",
        "        super(Controller, self).__init__()\n",
        "        self.fc = nn.Linear(z_dim + hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, z_t, h_t):\n",
        "        action_unscaled = self.fc(torch.cat([z_t, h_t], dim=-1))\n",
        "        steer = torch.tanh(action_unscaled[:, 0:1])\n",
        "        gas = torch.sigmoid(action_unscaled[:, 1:2])\n",
        "        brake = torch.sigmoid(action_unscaled[:, 2:3])\n",
        "        return torch.cat([steer, gas, brake], dim=-1)"
      ],
      "metadata": {
        "id": "HSqxeS6lOrNt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_obs(obs):\n",
        "    obs_tensor = torch.from_numpy(obs).permute(2, 0, 1).float() / 255.0\n",
        "    obs_tensor = obs_tensor.unsqueeze(0).to(device)\n",
        "    obs_resized = F.interpolate(obs_tensor, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "    return obs_resized"
      ],
      "metadata": {
        "id": "dL4iUFO6OojW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_agent():\n",
        "    print(\"Chargement des modèles entraînés...\")\n",
        "\n",
        "    # Charger le VAE\n",
        "    vae = CVAE(z_dim).to(device)\n",
        "    vae.load_state_dict(torch.load(VAE_MODEL_PATH, map_location=device), strict=False)\n",
        "    vae.eval()\n",
        "    # Charger le RNN\n",
        "    rnn = MDNRNN(z_dim, action_dim, hidden_dim, num_mixtures).to(device)\n",
        "    rnn.load_state_dict(torch.load(RNN_MODEL_PATH, map_location=device), strict=False)\n",
        "    rnn.eval()\n",
        "    controller = Controller(z_dim, hidden_dim, action_dim).to(device)\n",
        "    controller.load_state_dict(torch.load(CONTROLLER_SAVE_PATH, map_location=device))\n",
        "    controller.eval()\n",
        "\n",
        "    print(\"Modèles chargés. Lancement de l'environnement...\")\n",
        "\n",
        "    # --- MODIFICATION POUR LA VIDÉO ---\n",
        "    # 1. Utiliser 'rgb_array' au lieu de 'human'\n",
        "    env = gymnasium.make('CarRacing-v3', continuous=True, render_mode='rgb_array')\n",
        "    # 2. Envelopper l'environnement pour enregistrer une vidéo\n",
        "    # (On enregistre seulement le premier épisode pour l'exemple)\n",
        "    env = RecordVideo(env, video_folder=VIDEO_DIR, episode_trigger=lambda e: e == 0)\n",
        "\n",
        "    for episode in range(2): # Lancer 2 épisodes (seul le 1er sera enregistré)\n",
        "        print(f\"--- Début de l'Épisode {episode + 1} ---\")\n",
        "        total_reward = 0\n",
        "        obs, _ = env.reset()\n",
        "        h_t = torch.zeros(1, hidden_dim).to(device)\n",
        "        c_t = torch.zeros(1, hidden_dim).to(device)\n",
        "\n",
        "        while True:\n",
        "            with torch.no_grad():\n",
        "                obs_preprocessed = preprocess_obs(obs)\n",
        "                z_t = vae.reparameterize(*vae.encode(obs_preprocessed))\n",
        "                action_tensor = controller(z_t, h_t)\n",
        "                _, _, _, (h_t, c_t) = rnn(z_t, action_tensor, (h_t.unsqueeze(0), c_t.unsqueeze(0)))\n",
        "                h_t, c_t = h_t.squeeze(0), c_t.squeeze(0)\n",
        "\n",
        "            action_np = action_tensor.squeeze(0).cpu().numpy()\n",
        "            obs, reward, terminated, truncated, _ = env.step(action_np)\n",
        "            total_reward += reward\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "        print(f\"Épisode terminé. Récompense totale : {total_reward:.2f}\")\n",
        "\n",
        "    env.close()\n",
        "    print(\"Simulation terminée.\")\n",
        "\n",
        "    # --- 6. Afficher la vidéo dans Colab ---\n",
        "    print(\"Affichage de la vidéo enregistrée...\")\n",
        "    video_files = glob(os.path.join(VIDEO_DIR, \"*.mp4\"))\n",
        "\n",
        "    if video_files:\n",
        "        video_path = sorted(video_files)[-1] # Prendre la vidéo la plus récente\n",
        "        html = f\"\"\"\n",
        "        <video width=\"600\" controls>\n",
        "          <source src=\"{video_path}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "        \"\"\"\n",
        "        display(HTML(html))\n",
        "        print(f\"Vidéo affichée depuis {video_path}\")\n",
        "    else:\n",
        "        print(\"Aucun fichier vidéo trouvé.\")\n",
        "\n",
        "# --- Lancer le tout ---\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent()"
      ],
      "metadata": {
        "id": "NjmPyqYEOm5F",
        "colab": {
          "resources": {
            "http://localhost:8080/content/drive/My%20Drive/Colab%20Notebooks/World_model/videos/rl-video-episode-0.mp4": {
              "data": "",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "0"
                ]
              ],
              "status": 404,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "5a1302c7-636c-4319-eb51-83b4574a3314"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chargement des modèles entraînés...\n",
            "Modèles chargés. Lancement de l'environnement...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/drive/My Drive/Colab Notebooks/World_model/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Début de l'Épisode 1 ---\n",
            "Épisode terminé. Récompense totale : -25.37\n",
            "--- Début de l'Épisode 2 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Épisode terminé. Récompense totale : -28.81\n",
            "Simulation terminée.\n",
            "Affichage de la vidéo enregistrée...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        <video width=\"600\" controls>\n",
              "          <source src=\"/content/drive/My Drive/Colab Notebooks/World_model/videos/rl-video-episode-0.mp4\" type=\"video/mp4\">\n",
              "        </video>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vidéo affichée depuis /content/drive/My Drive/Colab Notebooks/World_model/videos/rl-video-episode-0.mp4\n"
          ]
        }
      ]
    }
  ]
}