{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJY/jZMcSSMM9SKXBa0V6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulienHelfenstein/World_model/blob/main/02_train_vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Définir le chemin racine de votre projet\n",
        "PROJECT_ROOT = \"/content/drive/My Drive/Colab Notebooks/World_model\""
      ],
      "metadata": {
        "id": "wcC7BqwXTZ0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "E_FOtgteMPTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Configuration et Hyperparamètres ---\n",
        "DATA_FILE = os.path.join(PROJECT_ROOT, \"data/carracing_data.npz\")\n",
        "MODEL_SAVE_PATH = os.path.join(PROJECT_ROOT, \"vae.pth\")\n",
        "z_dim = 32          # Dimension de l'espace latent (doit correspondre au RNN)\n",
        "image_channels = 3  # RGB\n",
        "learning_rate = 1e-3\n",
        "batch_size = 64     # Augmentez si vous avez plus de VRAM, diminuez si vous manquez de mémoire\n",
        "num_epochs = 10     # 10 époques est un début. 30-50 est mieux si vous avez le temps."
      ],
      "metadata": {
        "id": "xZdM3qRwKfx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Le Dataset Personnalisé ---\n",
        "#    Cette classe est la \"plomberie\" qui connecte\n",
        "#    votre fichier .npz au DataLoader de PyTorch.\n",
        "class CarRacingDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        print(f\"Chargement des données depuis {data_file}...\")\n",
        "        data = np.load(data_file)\n",
        "        # On ne prend que les observations, pas les actions\n",
        "        self.observations = data['observations']\n",
        "        print(f\"Données chargées. Shape: {self.observations.shape}\")\n",
        "\n",
        "        # Les images sont en (N, H, W, C). PyTorch (Conv2d)\n",
        "        # veut (N, C, H, W). Nous devons permuter les axes.\n",
        "        # (N, 64, 64, 3) -> (N, 3, 64, 64)\n",
        "        self.observations_tensor = torch.from_numpy(self.observations).permute(0, 3, 1, 2)\n",
        "        print(\"Données permutées pour PyTorch.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.observations_tensor)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Le DataLoader s'occupera de créer les batchs\n",
        "        return self.observations_tensor[idx]"
      ],
      "metadata": {
        "id": "vFT_VCd9KjVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Le Modèle CVAE (identique à avant) ---\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, z_dim, image_channels=3):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # --- Encodeur (Image -> Espace Latent) ---\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.flat_size = 256 * 4 * 4\n",
        "        self.fc_mu = nn.Linear(self.flat_size, z_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flat_size, z_dim)\n",
        "\n",
        "        # --- Décodeur (Espace Latent -> Image) ---\n",
        "        self.decoder_fc = nn.Linear(z_dim, self.flat_size)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, image_channels, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h_flat = h.view(-1, self.flat_size)\n",
        "        return self.fc_mu(h_flat), self.fc_logvar(h_flat)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = F.relu(self.decoder_fc(z))\n",
        "        h_unflat = h.view(-1, 256, 4, 4)\n",
        "        return self.decoder(h_unflat)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        recon_x = self.decode(z)\n",
        "        return recon_x, mu, log_var"
      ],
      "metadata": {
        "id": "dgMR4KhwKlms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "085L1yJ-KEd_"
      },
      "outputs": [],
      "source": [
        "# --- 4. Fonction de Perte (Loss) VAE (identique à avant) ---\n",
        "def vae_loss_function(recon_x, x, mu, log_var):\n",
        "    # Perte de Reconstruction (BCE). 'reduction=\"sum\"' est important.\n",
        "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "\n",
        "    # Perte de Régularisation (KLD)\n",
        "    kld = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "\n",
        "    return recon_loss + kld"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Script Principal d'Entraînement ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. Détecter le GPU\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Utilisation du device : {device}\")\n",
        "\n",
        "    # 2. Créer le Dataset et le DataLoader\n",
        "    dataset = CarRacingDataset(DATA_FILE)\n",
        "    data_loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2 # Utilise des sous-processus pour charger les données\n",
        "    )\n",
        "\n",
        "    # 3. Initialiser le Modèle et l'Optimiseur\n",
        "    model = CVAE(z_dim, image_channels).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    print(\"Début de l'entraînement du CVAE...\")\n",
        "    model.train() # Mettre le modèle en mode entraînement\n",
        "\n",
        "    # 4. Boucle d'Entraînement\n",
        "    for epoch in range(num_epochs):\n",
        "        total_epoch_loss = 0\n",
        "\n",
        "        # tqdm pour la barre de progression\n",
        "        pbar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "        for images in pbar:\n",
        "            images = images.to(device)\n",
        "\n",
        "            # --- Forward pass ---\n",
        "            recon_images, mu, log_var = model(images)\n",
        "\n",
        "            # --- Calcul de la perte ---\n",
        "            loss = vae_loss_function(recon_images, images, mu, log_var)\n",
        "\n",
        "            # --- Backward pass ---\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_epoch_loss += loss.item()\n",
        "            pbar.set_postfix(loss=f\"{loss.item()/len(images):.4f}\")\n",
        "\n",
        "        # Calculer la perte moyenne pour l'époque\n",
        "        avg_loss = total_epoch_loss / len(dataset)\n",
        "        print(f\"Fin Epoch {epoch+1}. Perte moyenne : {avg_loss:.4f}\")\n",
        "\n",
        "    # 5. Sauvegarder le modèle entraîné\n",
        "    print(\"Entraînement terminé.\")\n",
        "    print(f\"Sauvegarde du modèle dans {MODEL_SAVE_PATH}...\")\n",
        "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "    print(\"Modèle sauvegardé !\")"
      ],
      "metadata": {
        "id": "tCgvRfUqMGzN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}