{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG+YTV2SxPkRbyUfDPshFs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JulienHelfenstein/World_model/blob/main/04_train_controller.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Définir le chemin racine de votre projet\n",
        "PROJECT_ROOT = \"/content/drive/My Drive/Colab Notebooks/World_model\""
      ],
      "metadata": {
        "id": "TgcwSUZTTsOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNXlnZeVNvjq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import gymnasium\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Configuration et Hyperparamètres ---\n",
        "VAE_MODEL_PATH = os.path.join(PROJECT_ROOT, \"vae.pth\")\n",
        "RNN_MODEL_PATH = os.path.join(PROJECT_ROOT, \"rnn.pth\")\n",
        "CONTROLLER_SAVE_PATH = os.path.join(PROJECT_ROOT, \"controller.pth\")\n",
        "\n",
        "# Paramètres (doivent correspondre aux autres scripts)\n",
        "z_dim = 32\n",
        "action_dim = 3  # CarRacing: [steer, gas, brake]\n",
        "hidden_dim = 256 # Mémoire du LSTM\n",
        "num_mixtures = 5\n",
        "\n",
        "# Paramètres de l'entraînement du Contrôleur\n",
        "DREAM_HORIZON = 500 # Nombre d'étapes à simuler dans le rêve\n",
        "NUM_GENERATIONS = 100 # Nombre de \"générations\" d'entraînement\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "qR0wbochOD3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Définition des Modèles (Classes) ---\n",
        "\n",
        "# On a besoin de la définition du CVAE pour charger 'vae.pth'\n",
        "# (On n'a besoin que de l'encodeur)\n",
        "class CVAE(nn.Module):\n",
        "    def __init__(self, z_dim, image_channels=3):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(image_channels, 32, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n",
        "            nn.Conv2d(128, 256, 4, 2, 1), nn.ReLU()\n",
        "        )\n",
        "        self.flat_size = 256 * 4 * 4\n",
        "        self.fc_mu = nn.Linear(self.flat_size, z_dim)\n",
        "        self.fc_logvar = nn.Linear(self.flat_size, z_dim)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        h_flat = h.view(-1, self.flat_size)\n",
        "        return self.fc_mu(h_flat), self.fc_logvar(h_flat)\n",
        "\n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(0.5 * log_var); eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "# Définition du MDNRNN (MODIFIÉ pour inclure la récompense et le 'done')\n",
        "#\n",
        "class MDNRNN(nn.Module):\n",
        "    def __init__(self, z_dim, action_dim, hidden_dim, num_mixtures):\n",
        "        super(MDNRNN, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_mixtures = num_mixtures\n",
        "\n",
        "        input_dim = z_dim + action_dim\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Tête pour z_{t+1} (le MDN)\n",
        "        mdn_output_dim = num_mixtures * (1 + 2 * z_dim)\n",
        "        self.mdn_output = nn.Linear(hidden_dim, mdn_output_dim)\n",
        "\n",
        "        # --- NOUVELLES TÊTES ---\n",
        "        # Tête pour la récompense r_t (une simple valeur)\n",
        "        self.reward_head = nn.Linear(hidden_dim, 1)\n",
        "        # Tête pour le 'done' d_t (une probabilité)\n",
        "        self.done_head = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, z_t, a_t, hidden_state):\n",
        "        # z_t shape: (batch_size, z_dim)\n",
        "        # a_t shape: (batch_size, action_dim)\n",
        "        lstm_input = torch.cat([z_t, a_t], dim=-1).unsqueeze(1) # Ajoute dim 'seq'\n",
        "\n",
        "        lstm_output, next_hidden = self.lstm(lstm_input, hidden_state)\n",
        "        lstm_output = lstm_output.squeeze(1) # Enlève dim 'seq'\n",
        "\n",
        "        # Prédire les 3 sorties\n",
        "        mdn_params = self.mdn_output(lstm_output)\n",
        "        pred_reward = self.reward_head(lstm_output)\n",
        "        pred_done_logits = self.done_head(lstm_output)\n",
        "\n",
        "        return mdn_params, pred_reward, pred_done_logits, next_hidden\n",
        "\n",
        "    def sample_z_from_mdn(self, mdn_params):\n",
        "        # Fonction (simplifiée) pour piocher un z_{t+1} du mélange\n",
        "        # (Dans un vrai code, ce serait la logique MDN de la Phase 2)\n",
        "\n",
        "        # Pour cet exemple, on simplifie : on prend la moyenne (mu)\n",
        "        # de la première mixture comme \"prédiction\"\n",
        "        # (batch_size, num_mixtures * (1 + 2*z_dim))\n",
        "\n",
        "        # Ceci est une *simplification pédagogique* !\n",
        "        # Un vrai sample piocherait dans le mélange.\n",
        "        first_mu_start = self.num_mixtures\n",
        "        first_mu_end = self.num_mixtures + self.z_dim\n",
        "        pred_z_mu = mdn_params[..., first_mu_start:first_mu_end]\n",
        "        return pred_z_mu\n",
        "\n",
        "# Définition du Contrôleur (simple, comme avant)\n",
        "class Controller(nn.Module):\n",
        "    def __init__(self, z_dim, hidden_dim, action_dim):\n",
        "        super(Controller, self).__init__()\n",
        "        input_dim = z_dim + hidden_dim\n",
        "        self.fc = nn.Linear(input_dim, action_dim)\n",
        "\n",
        "    def forward(self, z_t, h_t):\n",
        "        controller_input = torch.cat([z_t, h_t], dim=-1)\n",
        "        action_unscaled = self.fc(controller_input)\n",
        "\n",
        "        # Actions pour CarRacing: [steer, gas, brake]\n",
        "        # On utilise tanh pour le volant (-1, 1)\n",
        "        # On utilise sigmoid pour l'accélérateur et le frein (0, 1)\n",
        "        steer = torch.tanh(action_unscaled[:, 0:1])\n",
        "        gas = torch.sigmoid(action_unscaled[:, 1:2])\n",
        "        brake = torch.sigmoid(action_unscaled[:, 2:3])\n",
        "\n",
        "        return torch.cat([steer, gas, brake], dim=-1)"
      ],
      "metadata": {
        "id": "q7wxWUKmOBSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. La Fonction de \"Rêve\" (le Cœur) ---\n",
        "def simulate_dream(controller, vae, rnn, z_0, h_0):\n",
        "    \"\"\"\n",
        "    Simule une trajectoire complète dans le rêve et retourne la récompense totale.\n",
        "    \"\"\"\n",
        "    controller.eval(); vae.eval(); rnn.eval() # Mode évaluation\n",
        "\n",
        "    total_reward = 0\n",
        "    z_t = z_0\n",
        "    h_t, c_t = h_0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(DREAM_HORIZON):\n",
        "            # 1. Le Contrôleur décide d'une action\n",
        "            a_t = controller(z_t, h_t)\n",
        "\n",
        "            # 2. Le RNN (Moteur de Rêve) prédit le futur\n",
        "            mdn_params, pred_reward, pred_done_logits, (h_t, c_t) = rnn(z_t, a_t, (h_t, c_t))\n",
        "\n",
        "            # 3. On \"pioch\" le prochain z_{t+1}\n",
        "            z_t = rnn.sample_z_from_mdn(mdn_params)\n",
        "\n",
        "            # 4. On accumule la récompense prédite\n",
        "            total_reward += pred_reward.item()\n",
        "\n",
        "            # 5. On vérifie si le rêve est \"terminé\"\n",
        "            if torch.sigmoid(pred_done_logits).item() > 0.5:\n",
        "                break # L'agent a \"rêvé\" qu'il crashait\n",
        "\n",
        "    return total_reward"
      ],
      "metadata": {
        "id": "dHNe46x4N-lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Script Principal d'Entraînement (Phase 3) ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 1. Charger les modèles VAE et RNN\n",
        "    print(\"Chargement des modèles VAE et RNN...\")\n",
        "    vae = CVAE(z_dim).to(device)\n",
        "    vae.load_state_dict(torch.load(VAE_MODEL_PATH, map_location=device))\n",
        "\n",
        "    rnn = MDNRNN(z_dim, action_dim, hidden_dim, num_mixtures).to(device)\n",
        "    rnn.load_state_dict(torch.load(RNN_MODEL_PATH, map_location=device))\n",
        "    print(\"Modèles chargés.\")\n",
        "\n",
        "    # 2. Initialiser le Contrôleur\n",
        "    controller = Controller(z_dim, hidden_dim, action_dim).to(device)\n",
        "\n",
        "    # 3. Obtenir un \"point de départ\" (z_0, h_0) du VRAI monde\n",
        "    # (C'est la seule fois qu'on touche à l'environnement)\n",
        "    print(\"Obtention d'un état de départ (z_0) du vrai monde...\")\n",
        "    env = gymnasium.make('CarRacing-v2')\n",
        "    obs, _ = env.reset()\n",
        "    obs_img = (torch.from_numpy(obs).permute(2, 0, 1).float() / 255.0).unsqueeze(0).to(device)\n",
        "    # Note: L'image doit être redimensionnée à 64x64 comme pour le VAE\n",
        "    # Ici, nous allons tricher et supposer que obs_img est 64x64\n",
        "    # (dans un vrai code, il faut importer la fct de redimensionnement)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # L'image est 96x96, le VAE s'attend à 64x64. On redimensionne.\n",
        "        obs_img_64 = F.interpolate(obs_img, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "        mu, log_var = vae.encode(obs_img_64)\n",
        "        z_0 = vae.reparameterize(mu, log_var)\n",
        "\n",
        "    h_0 = (torch.zeros(1, 1, hidden_dim).to(device),\n",
        "           torch.zeros(1, 1, hidden_dim).to(device))\n",
        "    env.close()\n",
        "\n",
        "    # 4. BOUCLE D'ENTRAÎNEMENT (CONCEPTUELLE)\n",
        "    # L'entraînement du Contrôleur n'est pas fait par backpropagation.\n",
        "    # On utilise un algorithme \"boîte noire\" (black-box),\n",
        "    # comme un Algorithme Génétique ou CMA-ES.\n",
        "\n",
        "    print(\"Début de l'entraînement 'boîte noire' du Contrôleur (conceptuel)...\")\n",
        "\n",
        "    # Ceci est une FAUSSE boucle d'optimisation pour l'exemple.\n",
        "    # Dans la vraie vie, vous utiliseriez une bibliothèque comme `cma`.\n",
        "\n",
        "    # On utilise Adam comme un \"faux\" optimiseur d'évolution\n",
        "    # C'est une astuce, pas la méthode standard, mais ça illustre l'idée\n",
        "    optimizer = torch.optim.Adam(controller.parameters(), lr=1e-3)\n",
        "\n",
        "    for generation in range(NUM_GENERATIONS):\n",
        "        controller.train()\n",
        "\n",
        "        # On simule le rêve\n",
        "        total_reward = simulate_dream(controller, vae, rnn, z_0, h_0)\n",
        "\n",
        "        # Puisqu'on veut MAXIMISER la récompense, on minimise son OPPOSÉ\n",
        "        loss = -total_reward\n",
        "\n",
        "        # On fait une passe \"backward\" (ceci est une astuce qui\n",
        "        # ne fonctionne qu'avec certains types de RL, mais\n",
        "        # illustre la mise à jour)\n",
        "        # Note: Pour que cela fonctionne, 'simulate_dream' ne devrait\n",
        "        # pas avoir @torch.no_grad() et les .item().\n",
        "\n",
        "        # ---- VRAIE FAÇON (Conceptuelle) ----\n",
        "        # 1. best_reward = -infinity\n",
        "        # 2. for i in range(50): # 50 agents par génération\n",
        "        # 3.   créer un 'new_controller' avec des poids bruités\n",
        "        # 4.   reward = simulate_dream(new_controller, ...)\n",
        "        # 5.   si reward > best_reward, garder ce contrôleur\n",
        "        # 6. 'controller' = meilleur contrôleur de la génération\n",
        "        # -----------------------------------\n",
        "\n",
        "        # On va juste afficher la récompense pour l'exemple\n",
        "        print(f\"Génération {generation+1}/{NUM_GENERATIONS}, Récompense de Rêve: {total_reward:.2f}\")\n",
        "\n",
        "        # (Ici, on ne met pas vraiment le contrôleur à jour,\n",
        "        # car il manque l'algorithme d'évolution)\n",
        "\n",
        "    # 5. Sauvegarder le meilleur contrôleur\n",
        "    print(\"Entraînement terminé.\")\n",
        "    torch.save(controller.state_dict(), CONTROLLER_SAVE_PATH)\n",
        "    print(f\"Modèle Contrôleur sauvegardé dans {CONTROLLER_SAVE_PATH}\")"
      ],
      "metadata": {
        "id": "LpBJZFnJN5l1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}